---
title: ELK
date: 2017-08-14 14:16:28
tags: [ELK]
categories: 技术
---

## 案例
## 背景介绍
本来想学用一下flume， 把多台服务器的日志做统一处理，查阅资料后发现ELK更适合
就尝试着搭建了ELK服务， 其实是ELKF（Elasticsearch logstash kibana Filebeat）

日志来源于两台服务器上的2个（4个： 2*2）应用； 日志采用log4j格式打印，目前设置日志级别
为INFO，因此日志量比较大。 

解决的问题： 登录多个服务器上查找日志

### 环境&部署
filebeat分别部署在2台应用服务器上，logstash单独部署（grok耗费资源），es和kibana部署在一台服务器（es作为存储 需提前分配存储空间）

<!-- more -->

## Filebeat
### 介绍
使用filebeat是因为 主要担心logstash与应用服务器 抢占资源。
filebeat支持直接输出到elasticsearch（日志文件为json格式可以直接输出到es），也可以输出
到logstash（本案例使用grok解析日志格式），也支持Redis 和 RocketMQ


### 安装 -linux x86_64
```bash
wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.0.0-beta1-linux-x86_64.tar.gz
```
[官网下载 其他版本](https://www.elastic.co/downloads/beats/filebeat)

### 配置
编辑 filebeat.yml 直接按照注释的说明就可以配置
文件路径支持通配符
```bash
# 日志文件路径
-path /opt/../../../server*/System*.log

# elasticsearch 配置

# logstatsh 配置
```

### 运行
``` bash
./filebeat -e -c filebeat.yml
nohup ./filebeat -e -c filebeat.yml >/dev/null 2>&1 &
```

## logstash
### 介绍
logstash 可以读流文件（socket读取），也可以多个logstash agent输出到logstash汇总应用
本案例主要使用logstash解决两个问题： 
1. grok解析日志 生成json格式
2. 多行输入的解析处理

### 安装
```bash
wget https://artifacts.elastic.co/downloads/logstash/logstash-5.5.1.tar.gz
```

依赖： jdk 1.8

### 配置 config文件
config文件主要定义用户的处理规则
注意： conf目录下的配置文件是logstash的基础配置文件，主要包括jvm配置和服务配置
主要的工作量： 配置grok表达式以解析应用日志。 

参考[官网的配置示例](https://www.elastic.co/guide/en/logstash/current/logstash-config-for-filebeat-modules.html)
最终的配置如下：
```bash

```

[grok说明](https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html)
说明： 自定义的pattern 可自定义存储，比如：patterns/extra, grok引入即可使用
```bash
# contents of ./patterns/postfix:
POSTFIX_QUEUEID [0-9A-F]{10,11}
# 
filter {
  grok {
    patterns_dir => ["./patterns"]
    match => { "message" => "%{SYSLOGBASE} %{POSTFIX_QUEUEID:queue_id}: %{GREEDYDATA:syslog_message}" }
  }
}
```
#### 正则说明
\s：匹配任何不可见字符，包括空格、制表符、换页符等等。等价于[ \f\n\r\t\v]。+表示匹配次数为1次或者多次

(?:pattern) 
非获取匹配，匹配pattern但不获取匹配结果，不进行存储供以后使用。这在使用或字符“(|)”来组合一个模式的各个部分是很有用。例如“industr(?:y|ies)”就是一个比“industry|industries”更简略的表达式。
(?=pattern)
非获取匹配，正向肯定预查，在任何匹配pattern的字符串开始处匹配查找字符串，该匹配不需要获取供以后使用。例如，“Windows(?=95|98|NT|2000)”能匹配“Windows2000”中的“Windows”，但不能匹配“Windows3.1”中的“Windows”。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。
(?!pattern)
非获取匹配，正向否定预查，在任何不匹配pattern的字符串开始处匹配查找字符串，该匹配不需要获取供以后使用。例如“Windows(?!95|98|NT|2000)”能匹配“Windows3.1”中的“Windows”，但不能匹配“Windows2000”中的“Windows”。
(?<=pattern)
非获取匹配，反向肯定预查，与正向肯定预查类似，只是方向相反。例如，“(?<=95|98|NT|2000)Windows”能匹配“2000Windows”中的“Windows”，但不能匹配“3.1Windows”中的“Windows”。
(?<!pattern)
非获取匹配，反向否定预查，与正向否定预查类似，只是方向相反。例如“(?<!95|98|NT|2000)Windows”能匹配“3.1Windows”中的“Windows”，但不能匹配“2000Windows”中的“Windows”。这个地方不正确，有问题 

\.\d+：表示点后面跟一个或者多个 数字，(?:\.\d+)?表示点后面跟一个或多个数字这种情况出现0次或者多次，如果为0次，则request_time为一个整数。所以匹配到的结果可能为123.456或者123或者123.4.5.6，这些都满足条件

分组语法 捕获
(exp) 匹配exp,并捕获文本到自动命名的组里
(?<name>exp) 匹配exp,并捕获文本到名称为name的组里，也可以写成(?'name'exp)
(?:exp) 匹配exp,不捕获匹配的文本
位置指定
(?=exp) 匹配exp前面的位置
(?<=exp) 匹配exp后面的位置
(?!exp) 匹配后面跟的不是exp的位置
(?<!exp) 匹配前面不是exp的位置
注释
(?#comment) 这种类型的组不对正则表达式的处理产生任何影响，只是为了提供让人阅读注释

#### grok使用
[测试网站：grokdebug.herokuapp.com](http://grokdebug.herokuapp.com/)
[参考示例](http://grokdebug.herokuapp.com/patterns#)

### 运行
```bash
bin/logstash -f logstash.conf [-path conf]

nohup bin/logstash -f etc/ &
```

[详细的命令行参数说明](https://www.elastic.co/guide/en/logstash/5.1/running-logstash-command-line.html)

## ES
### 介绍

### 安装
```bash
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.5.1.tar.gz 
```
依赖 jdk1.8

### 运行
```bash
bin/elasticsearch
bin/elasticsearch -d  #后台运行
```
说明： 
1. 不能使用root 启动，为es单独建用户
2. vim /etc/sysctl.conf  
vm.max_map_count=655360
3. vim /etc/security/limits.conf
* hard nofile 65536  
* soft nofile 65536

### es使用
curl --silent 'http://127.0.0.1:9200/_cat/indices' | cut -d\ -f2

/_aliases?pretty=1

/_stats
/_stats/{metric}
/_stats/{metric}/{indexMetric}
/{index}/_stats
/{index}/_stats/{metric}

### Elasticsearch关键概念

根据官网自己的介绍，Elasticsearch是一个分布式搜索服务，提供Restful API，底层基于Lucene，采用多shard的方式保证数据安全，并且提供自动resharding的功能，加之github等大型的站点也采用Elasticsearch作为其搜索服务，我们决定在项目中使用Elasticsearch。

数据：
Index：Elasticsearch用来存储数据的逻辑区域，它类似于关系型数据库中的db概念。一个index可以在一个或者多个shard上面，同时一个shard也可能会有多个replicas。
Document：Elasticsearch里面存储的实体数据，类似于关系数据中一个table里面的一行数据。
document由多个field组成，不同的document里面同名的field一定具有相同的类型。document里面field可以重复出现，也就是一个field会有多个值，即multivalued。
Document type：为了查询需要，一个index可能会有多种document，也就是document type，但需要注意，不同document里面同名的field一定要是相同类型的。
Mapping：存储field的相关映射信息，不同document type会有不同的mapping。
对于熟悉MySQL的童鞋，我们只需要大概认为Index就是一个db，document就是一行数据，field就是table的column，mapping就是table的定义，而document type就是一个table就可以了。

服务层：
Node: 一个server实例。
Cluster：多个node组成cluster。
Shard：数据分片，一个index可能会存在于多个shards，不同shards可能在不同nodes。
Replica：shard的备份，有一个primary shard，其余的叫做replica shards。
Elasticsearch之所以能动态resharding，主要在于它最开始就预先分配了多个shards（貌似是1024），然后以shard为单位进行数据迁移。这个做法其实在分布式领域非常的普遍，codis就是使用了1024个slot来进行数据迁移。

因为任意一个index都可配置多个replica，通过冗余备份的方式保证了数据的安全性，同时replica也能分担读压力，类似于MySQL中的slave

### Lucene关键概念

Document：用来索引和搜索的主要数据源，包含一个或者多个Field，而这些Field则包含我们跟Lucene交互的数据。
Field：Document的一个组成部分，有两个部分组成，name和value。
Term：不可分割的单词，搜索最小单元。
Token：一个Term呈现方式，包含这个Term的内容，在文档中的起始位置，以及类型。

作者：siddontang
链接：http://www.jianshu.com/p/05cff717563c
來源：简书
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

## kibana
### 介绍

### 安装 linux x86_64
```bash
wget https://artifacts.elastic.co/downloads/kibana/kibana-5.5.1-linux-x86_64.tar.gz
```
[其他版本下载](https://www.elastic.co/downloads/kibana)

### 配置
 config/kibana.yml
 Set elasticsearch.url to point at your Elasticsearch instance

### 运行
```bash
nohup bin/kibana &
```

### 使用
#### 索引设置
filebeat-*
日志正常解析为多个域后， kibana会自动识别field并作为查询条件

#### query

## 附：log4j 输出格式

    %n - 换行
    %m - 日志内容   
    %p - 日志级别(FATAL,   ERROR,   WARN,   INFO,   DEBUG   or   custom)    
    %r - 程序启动到现在的毫秒数 
    %% - percent   sign   in   output
    %t - 当前线程名
    %d   -  日期和时间, 
        常用的格式有 %d{DATE}, %d{ABSOLUTE}, %d{HH:mm:ss,SSS}, %d{ddMMyyyy HH:mm:ss,SSS}。。。
    %l - 同 %F%L%C%M
        %F - java源文件名
    %L - java源码行数
        %C - java类名,%C{1} 输出最后一个元素
        %M-java方法名

## 待补充： 
1. es集群配置
2. kibana es认证设置
3. es中文分词